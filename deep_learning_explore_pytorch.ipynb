{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e897adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a073a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89cec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7038, 0.2525],\n",
      "         [0.1881, 0.1776],\n",
      "         [0.3897, 0.2838]],\n",
      "\n",
      "        [[0.3392, 0.7200],\n",
      "         [0.3295, 0.2739],\n",
      "         [0.8637, 0.3751]],\n",
      "\n",
      "        [[0.3129, 0.9907],\n",
      "         [0.1120, 0.7530],\n",
      "         [0.1531, 0.6820]],\n",
      "\n",
      "        [[0.8642, 0.4108],\n",
      "         [0.3396, 0.5499],\n",
      "         [0.2431, 0.6501]],\n",
      "\n",
      "        [[0.3468, 0.4088],\n",
      "         [0.8634, 0.5926],\n",
      "         [0.4690, 0.9144]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53936f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b83845e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc8ad39fe0744cda2f2370196c5cb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b659ef8b7cf74f048844e1f0fb29992a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204992330631408b910d7cafee603608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d59979ad55b443997d52c75dde26188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f75e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26649ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f277507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06612028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([1, 1, 28, 28])\n",
      "Shape of y: torch.Size([1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc7894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=80, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=80, out_features=80, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=80, out_features=40, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=40, out_features=20, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=20, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# To create model, must be done manually in a class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to('cpu')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71206833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer (recall, model seeks to minimize loss using optimizer)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b2b70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that performs the fitting of model\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to('cpu'), y.to('cpu')\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f4cf37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to('cpu'), y.to('cpu')\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd2bcfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.235820  [    0/60000]\n",
      "loss: 2.243317  [  100/60000]\n",
      "loss: 2.467592  [  200/60000]\n",
      "loss: 2.227604  [  300/60000]\n",
      "loss: 2.447607  [  400/60000]\n",
      "loss: 2.298117  [  500/60000]\n",
      "loss: 2.223757  [  600/60000]\n",
      "loss: 2.274035  [  700/60000]\n",
      "loss: 2.221588  [  800/60000]\n",
      "loss: 2.228010  [  900/60000]\n",
      "loss: 2.550555  [ 1000/60000]\n",
      "loss: 2.213685  [ 1100/60000]\n",
      "loss: 2.413570  [ 1200/60000]\n",
      "loss: 2.153628  [ 1300/60000]\n",
      "loss: 2.151630  [ 1400/60000]\n",
      "loss: 2.238556  [ 1500/60000]\n",
      "loss: 2.545982  [ 1600/60000]\n",
      "loss: 2.406492  [ 1700/60000]\n",
      "loss: 2.430584  [ 1800/60000]\n",
      "loss: 2.425204  [ 1900/60000]\n",
      "loss: 2.271270  [ 2000/60000]\n",
      "loss: 2.524377  [ 2100/60000]\n",
      "loss: 2.298870  [ 2200/60000]\n",
      "loss: 2.206094  [ 2300/60000]\n",
      "loss: 2.272128  [ 2400/60000]\n",
      "loss: 2.520601  [ 2500/60000]\n",
      "loss: 2.255854  [ 2600/60000]\n",
      "loss: 2.413193  [ 2700/60000]\n",
      "loss: 2.256066  [ 2800/60000]\n",
      "loss: 2.288887  [ 2900/60000]\n",
      "loss: 2.268605  [ 3000/60000]\n",
      "loss: 2.245214  [ 3100/60000]\n",
      "loss: 2.400716  [ 3200/60000]\n",
      "loss: 2.407554  [ 3300/60000]\n",
      "loss: 2.301492  [ 3400/60000]\n",
      "loss: 2.309409  [ 3500/60000]\n",
      "loss: 2.269058  [ 3600/60000]\n",
      "loss: 2.235857  [ 3700/60000]\n",
      "loss: 2.357502  [ 3800/60000]\n",
      "loss: 2.351385  [ 3900/60000]\n",
      "loss: 2.175491  [ 4000/60000]\n",
      "loss: 2.266773  [ 4100/60000]\n",
      "loss: 2.184819  [ 4200/60000]\n",
      "loss: 2.332974  [ 4300/60000]\n",
      "loss: 2.304469  [ 4400/60000]\n",
      "loss: 2.487536  [ 4500/60000]\n",
      "loss: 2.336371  [ 4600/60000]\n",
      "loss: 2.278245  [ 4700/60000]\n",
      "loss: 2.242224  [ 4800/60000]\n",
      "loss: 2.332870  [ 4900/60000]\n",
      "loss: 2.170121  [ 5000/60000]\n",
      "loss: 2.165829  [ 5100/60000]\n",
      "loss: 2.283404  [ 5200/60000]\n",
      "loss: 2.174001  [ 5300/60000]\n",
      "loss: 2.394535  [ 5400/60000]\n",
      "loss: 2.310555  [ 5500/60000]\n",
      "loss: 2.234830  [ 5600/60000]\n",
      "loss: 2.401144  [ 5700/60000]\n",
      "loss: 2.286569  [ 5800/60000]\n",
      "loss: 2.390522  [ 5900/60000]\n",
      "loss: 2.228866  [ 6000/60000]\n",
      "loss: 2.257615  [ 6100/60000]\n",
      "loss: 2.368850  [ 6200/60000]\n",
      "loss: 2.362822  [ 6300/60000]\n",
      "loss: 2.418995  [ 6400/60000]\n",
      "loss: 2.281460  [ 6500/60000]\n",
      "loss: 2.192665  [ 6600/60000]\n",
      "loss: 2.407661  [ 6700/60000]\n",
      "loss: 2.228418  [ 6800/60000]\n",
      "loss: 2.283306  [ 6900/60000]\n",
      "loss: 2.298179  [ 7000/60000]\n",
      "loss: 2.288868  [ 7100/60000]\n",
      "loss: 2.271756  [ 7200/60000]\n",
      "loss: 2.307872  [ 7300/60000]\n",
      "loss: 2.307017  [ 7400/60000]\n",
      "loss: 2.375410  [ 7500/60000]\n",
      "loss: 2.285886  [ 7600/60000]\n",
      "loss: 2.247777  [ 7700/60000]\n",
      "loss: 2.282985  [ 7800/60000]\n",
      "loss: 2.370166  [ 7900/60000]\n",
      "loss: 2.359528  [ 8000/60000]\n",
      "loss: 2.251243  [ 8100/60000]\n",
      "loss: 2.291601  [ 8200/60000]\n",
      "loss: 2.305728  [ 8300/60000]\n",
      "loss: 2.322547  [ 8400/60000]\n",
      "loss: 2.247512  [ 8500/60000]\n",
      "loss: 2.327698  [ 8600/60000]\n",
      "loss: 2.287856  [ 8700/60000]\n",
      "loss: 2.279918  [ 8800/60000]\n",
      "loss: 2.386403  [ 8900/60000]\n",
      "loss: 2.243081  [ 9000/60000]\n",
      "loss: 2.310011  [ 9100/60000]\n",
      "loss: 2.193310  [ 9200/60000]\n",
      "loss: 2.268154  [ 9300/60000]\n",
      "loss: 2.268083  [ 9400/60000]\n",
      "loss: 2.228528  [ 9500/60000]\n",
      "loss: 2.336958  [ 9600/60000]\n",
      "loss: 2.231890  [ 9700/60000]\n",
      "loss: 2.397938  [ 9800/60000]\n",
      "loss: 2.309854  [ 9900/60000]\n",
      "loss: 2.260135  [10000/60000]\n",
      "loss: 2.325629  [10100/60000]\n",
      "loss: 2.322041  [10200/60000]\n",
      "loss: 2.330588  [10300/60000]\n",
      "loss: 2.399788  [10400/60000]\n",
      "loss: 2.222015  [10500/60000]\n",
      "loss: 2.240808  [10600/60000]\n",
      "loss: 2.331872  [10700/60000]\n",
      "loss: 2.329978  [10800/60000]\n",
      "loss: 2.255989  [10900/60000]\n",
      "loss: 2.221329  [11000/60000]\n",
      "loss: 2.246882  [11100/60000]\n",
      "loss: 2.229214  [11200/60000]\n",
      "loss: 2.305351  [11300/60000]\n",
      "loss: 2.195439  [11400/60000]\n",
      "loss: 2.401909  [11500/60000]\n",
      "loss: 2.343132  [11600/60000]\n",
      "loss: 2.337072  [11700/60000]\n",
      "loss: 2.252549  [11800/60000]\n",
      "loss: 2.281649  [11900/60000]\n",
      "loss: 2.171081  [12000/60000]\n",
      "loss: 2.272313  [12100/60000]\n",
      "loss: 2.261101  [12200/60000]\n",
      "loss: 2.263210  [12300/60000]\n",
      "loss: 2.300036  [12400/60000]\n",
      "loss: 2.255380  [12500/60000]\n",
      "loss: 2.274723  [12600/60000]\n",
      "loss: 2.274073  [12700/60000]\n",
      "loss: 2.389852  [12800/60000]\n",
      "loss: 2.288873  [12900/60000]\n",
      "loss: 2.193292  [13000/60000]\n",
      "loss: 2.349772  [13100/60000]\n",
      "loss: 2.349335  [13200/60000]\n",
      "loss: 2.390603  [13300/60000]\n",
      "loss: 2.372239  [13400/60000]\n",
      "loss: 2.292959  [13500/60000]\n",
      "loss: 2.146770  [13600/60000]\n",
      "loss: 2.180929  [13700/60000]\n",
      "loss: 2.385451  [13800/60000]\n",
      "loss: 2.216817  [13900/60000]\n",
      "loss: 2.184715  [14000/60000]\n",
      "loss: 2.395732  [14100/60000]\n",
      "loss: 2.265161  [14200/60000]\n",
      "loss: 2.283591  [14300/60000]\n",
      "loss: 2.243150  [14400/60000]\n",
      "loss: 2.318725  [14500/60000]\n",
      "loss: 2.160932  [14600/60000]\n",
      "loss: 2.302429  [14700/60000]\n",
      "loss: 2.334451  [14800/60000]\n",
      "loss: 2.156242  [14900/60000]\n",
      "loss: 2.391328  [15000/60000]\n",
      "loss: 2.299428  [15100/60000]\n",
      "loss: 2.162394  [15200/60000]\n",
      "loss: 2.137680  [15300/60000]\n",
      "loss: 2.289293  [15400/60000]\n",
      "loss: 2.220205  [15500/60000]\n",
      "loss: 2.071585  [15600/60000]\n",
      "loss: 2.029691  [15700/60000]\n",
      "loss: 2.381194  [15800/60000]\n",
      "loss: 2.129396  [15900/60000]\n",
      "loss: 2.297676  [16000/60000]\n",
      "loss: 2.241033  [16100/60000]\n",
      "loss: 2.319744  [16200/60000]\n",
      "loss: 2.069197  [16300/60000]\n",
      "loss: 2.379484  [16400/60000]\n",
      "loss: 2.269724  [16500/60000]\n",
      "loss: 2.286909  [16600/60000]\n",
      "loss: 2.205522  [16700/60000]\n",
      "loss: 2.132631  [16800/60000]\n",
      "loss: 2.233076  [16900/60000]\n",
      "loss: 2.234624  [17000/60000]\n",
      "loss: 2.211629  [17100/60000]\n",
      "loss: 1.970304  [17200/60000]\n",
      "loss: 2.262929  [17300/60000]\n",
      "loss: 2.376974  [17400/60000]\n",
      "loss: 2.325415  [17500/60000]\n",
      "loss: 2.295809  [17600/60000]\n",
      "loss: 2.308519  [17700/60000]\n",
      "loss: 2.144080  [17800/60000]\n",
      "loss: 1.986247  [17900/60000]\n",
      "loss: 2.214073  [18000/60000]\n",
      "loss: 2.103952  [18100/60000]\n",
      "loss: 2.185528  [18200/60000]\n",
      "loss: 2.316083  [18300/60000]\n",
      "loss: 1.939521  [18400/60000]\n",
      "loss: 2.128709  [18500/60000]\n",
      "loss: 2.386348  [18600/60000]\n",
      "loss: 1.989888  [18700/60000]\n",
      "loss: 1.825427  [18800/60000]\n",
      "loss: 2.351047  [18900/60000]\n",
      "loss: 2.172940  [19000/60000]\n",
      "loss: 1.686404  [19100/60000]\n",
      "loss: 2.373874  [19200/60000]\n",
      "loss: 2.080749  [19300/60000]\n",
      "loss: 1.613108  [19400/60000]\n",
      "loss: 2.206711  [19500/60000]\n",
      "loss: 2.241536  [19600/60000]\n",
      "loss: 1.992961  [19700/60000]\n",
      "loss: 1.945684  [19800/60000]\n",
      "loss: 0.414770  [19900/60000]\n",
      "loss: 2.433453  [20000/60000]\n",
      "loss: 2.417024  [20100/60000]\n",
      "loss: 2.335269  [20200/60000]\n",
      "loss: 2.175777  [20300/60000]\n",
      "loss: 2.164654  [20400/60000]\n",
      "loss: 2.249681  [20500/60000]\n",
      "loss: 1.759642  [20600/60000]\n",
      "loss: 1.589499  [20700/60000]\n",
      "loss: 2.110953  [20800/60000]\n",
      "loss: 1.633014  [20900/60000]\n",
      "loss: 1.894004  [21000/60000]\n",
      "loss: 1.710424  [21100/60000]\n",
      "loss: 1.439342  [21200/60000]\n",
      "loss: 1.490361  [21300/60000]\n",
      "loss: 1.336037  [21400/60000]\n",
      "loss: 1.731119  [21500/60000]\n",
      "loss: 0.659540  [21600/60000]\n",
      "loss: 2.779067  [21700/60000]\n",
      "loss: 0.286231  [21800/60000]\n",
      "loss: 1.472928  [21900/60000]\n",
      "loss: 2.625471  [22000/60000]\n",
      "loss: 1.799150  [22100/60000]\n",
      "loss: 2.084278  [22200/60000]\n",
      "loss: 1.614741  [22300/60000]\n",
      "loss: 1.768021  [22400/60000]\n",
      "loss: 1.642072  [22500/60000]\n",
      "loss: 1.367798  [22600/60000]\n",
      "loss: 1.186625  [22700/60000]\n",
      "loss: 1.501519  [22800/60000]\n",
      "loss: 1.181311  [22900/60000]\n",
      "loss: 0.552350  [23000/60000]\n",
      "loss: 2.091637  [23100/60000]\n",
      "loss: 1.769194  [23200/60000]\n",
      "loss: 1.457094  [23300/60000]\n",
      "loss: 2.154442  [23400/60000]\n",
      "loss: 1.060607  [23500/60000]\n",
      "loss: 1.129278  [23600/60000]\n",
      "loss: 2.088932  [23700/60000]\n",
      "loss: 1.282637  [23800/60000]\n",
      "loss: 1.458215  [23900/60000]\n",
      "loss: 1.782078  [24000/60000]\n",
      "loss: 1.347858  [24100/60000]\n",
      "loss: 0.510300  [24200/60000]\n",
      "loss: 1.596373  [24300/60000]\n",
      "loss: 1.132710  [24400/60000]\n",
      "loss: 0.412434  [24500/60000]\n",
      "loss: 1.202449  [24600/60000]\n",
      "loss: 0.093726  [24700/60000]\n",
      "loss: 0.555041  [24800/60000]\n",
      "loss: 0.734204  [24900/60000]\n",
      "loss: 2.842552  [25000/60000]\n",
      "loss: 2.111595  [25100/60000]\n",
      "loss: 2.250633  [25200/60000]\n",
      "loss: 0.726187  [25300/60000]\n",
      "loss: 1.766629  [25400/60000]\n",
      "loss: 0.142525  [25500/60000]\n",
      "loss: 0.521722  [25600/60000]\n",
      "loss: 0.665096  [25700/60000]\n",
      "loss: 5.481361  [25800/60000]\n",
      "loss: 1.716366  [25900/60000]\n",
      "loss: 0.592743  [26000/60000]\n",
      "loss: 1.974891  [26100/60000]\n",
      "loss: 1.126027  [26200/60000]\n",
      "loss: 2.122686  [26300/60000]\n",
      "loss: 0.863774  [26400/60000]\n",
      "loss: 0.704866  [26500/60000]\n",
      "loss: 4.424139  [26600/60000]\n",
      "loss: 1.480783  [26700/60000]\n",
      "loss: 0.967901  [26800/60000]\n",
      "loss: 2.194528  [26900/60000]\n",
      "loss: 1.981012  [27000/60000]\n",
      "loss: 0.911262  [27100/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.623784  [27200/60000]\n",
      "loss: 0.214937  [27300/60000]\n",
      "loss: 0.952616  [27400/60000]\n",
      "loss: 0.743447  [27500/60000]\n",
      "loss: 0.645838  [27600/60000]\n",
      "loss: 2.412195  [27700/60000]\n",
      "loss: 0.867474  [27800/60000]\n",
      "loss: 0.606958  [27900/60000]\n",
      "loss: 0.134277  [28000/60000]\n",
      "loss: 0.106250  [28100/60000]\n",
      "loss: 1.203400  [28200/60000]\n",
      "loss: 0.285153  [28300/60000]\n",
      "loss: 0.342796  [28400/60000]\n",
      "loss: 0.989748  [28500/60000]\n",
      "loss: 0.487895  [28600/60000]\n",
      "loss: 0.478303  [28700/60000]\n",
      "loss: 0.425999  [28800/60000]\n",
      "loss: 0.734009  [28900/60000]\n",
      "loss: 0.544491  [29000/60000]\n",
      "loss: 1.688296  [29100/60000]\n",
      "loss: 0.537522  [29200/60000]\n",
      "loss: 2.000805  [29300/60000]\n",
      "loss: 1.755341  [29400/60000]\n",
      "loss: 0.442056  [29500/60000]\n",
      "loss: 0.639791  [29600/60000]\n",
      "loss: 0.986411  [29700/60000]\n",
      "loss: 2.109319  [29800/60000]\n",
      "loss: 1.667615  [29900/60000]\n",
      "loss: 0.571541  [30000/60000]\n",
      "loss: 0.545271  [30100/60000]\n",
      "loss: 0.181887  [30200/60000]\n",
      "loss: 0.312464  [30300/60000]\n",
      "loss: 1.035719  [30400/60000]\n",
      "loss: 0.866739  [30500/60000]\n",
      "loss: 1.630775  [30600/60000]\n",
      "loss: 0.361801  [30700/60000]\n",
      "loss: 1.009595  [30800/60000]\n",
      "loss: 2.406209  [30900/60000]\n",
      "loss: 2.209965  [31000/60000]\n",
      "loss: 1.440621  [31100/60000]\n",
      "loss: 5.648689  [31200/60000]\n",
      "loss: 1.337988  [31300/60000]\n",
      "loss: 1.154948  [31400/60000]\n",
      "loss: 1.616880  [31500/60000]\n",
      "loss: 4.865067  [31600/60000]\n",
      "loss: 0.484252  [31700/60000]\n",
      "loss: 0.290587  [31800/60000]\n",
      "loss: 1.664147  [31900/60000]\n",
      "loss: 0.764322  [32000/60000]\n",
      "loss: 0.729727  [32100/60000]\n",
      "loss: 0.636981  [32200/60000]\n",
      "loss: 0.992208  [32300/60000]\n",
      "loss: 1.292323  [32400/60000]\n",
      "loss: 0.217079  [32500/60000]\n",
      "loss: 0.644436  [32600/60000]\n",
      "loss: 0.166523  [32700/60000]\n",
      "loss: 0.115427  [32800/60000]\n",
      "loss: 1.249739  [32900/60000]\n",
      "loss: 1.134155  [33000/60000]\n",
      "loss: 0.031341  [33100/60000]\n",
      "loss: 0.766799  [33200/60000]\n",
      "loss: 0.809061  [33300/60000]\n",
      "loss: 0.586523  [33400/60000]\n",
      "loss: 0.834639  [33500/60000]\n",
      "loss: 0.011269  [33600/60000]\n",
      "loss: 1.186764  [33700/60000]\n",
      "loss: 0.128202  [33800/60000]\n",
      "loss: 0.398806  [33900/60000]\n",
      "loss: 0.621023  [34000/60000]\n",
      "loss: 0.962321  [34100/60000]\n",
      "loss: 0.547057  [34200/60000]\n",
      "loss: 1.154057  [34300/60000]\n",
      "loss: 0.321337  [34400/60000]\n",
      "loss: 1.691843  [34500/60000]\n",
      "loss: 0.836932  [34600/60000]\n",
      "loss: 0.384967  [34700/60000]\n",
      "loss: 2.761591  [34800/60000]\n",
      "loss: 0.641714  [34900/60000]\n",
      "loss: 0.028549  [35000/60000]\n",
      "loss: 0.925418  [35100/60000]\n",
      "loss: 0.042326  [35200/60000]\n",
      "loss: 1.032677  [35300/60000]\n",
      "loss: 0.006902  [35400/60000]\n",
      "loss: 1.722901  [35500/60000]\n",
      "loss: 0.036017  [35600/60000]\n",
      "loss: 0.001769  [35700/60000]\n",
      "loss: 0.009003  [35800/60000]\n",
      "loss: 0.016716  [35900/60000]\n",
      "loss: 0.321117  [36000/60000]\n",
      "loss: 0.550149  [36100/60000]\n",
      "loss: 0.305216  [36200/60000]\n",
      "loss: 0.398795  [36300/60000]\n",
      "loss: 0.268755  [36400/60000]\n",
      "loss: 0.384302  [36500/60000]\n",
      "loss: 0.160127  [36600/60000]\n",
      "loss: 0.052324  [36700/60000]\n",
      "loss: 0.314874  [36800/60000]\n",
      "loss: 1.191644  [36900/60000]\n",
      "loss: 0.098883  [37000/60000]\n",
      "loss: 1.939813  [37100/60000]\n",
      "loss: 0.011267  [37200/60000]\n",
      "loss: 1.267287  [37300/60000]\n",
      "loss: 0.509841  [37400/60000]\n",
      "loss: 0.052318  [37500/60000]\n",
      "loss: 0.440182  [37600/60000]\n",
      "loss: 0.178684  [37700/60000]\n",
      "loss: 0.160231  [37800/60000]\n",
      "loss: 0.157155  [37900/60000]\n",
      "loss: 0.360977  [38000/60000]\n",
      "loss: 0.002881  [38100/60000]\n",
      "loss: 0.000319  [38200/60000]\n",
      "loss: 0.152522  [38300/60000]\n",
      "loss: 0.041164  [38400/60000]\n",
      "loss: 0.278850  [38500/60000]\n",
      "loss: 1.143796  [38600/60000]\n",
      "loss: 3.289570  [38700/60000]\n",
      "loss: 0.291496  [38800/60000]\n",
      "loss: 0.050735  [38900/60000]\n",
      "loss: 0.506235  [39000/60000]\n",
      "loss: 1.030746  [39100/60000]\n",
      "loss: 0.001829  [39200/60000]\n",
      "loss: 0.031833  [39300/60000]\n",
      "loss: 1.335387  [39400/60000]\n",
      "loss: 0.336924  [39500/60000]\n",
      "loss: 3.698885  [39600/60000]\n",
      "loss: 0.961856  [39700/60000]\n",
      "loss: 0.058856  [39800/60000]\n",
      "loss: 0.484719  [39900/60000]\n",
      "loss: 0.048546  [40000/60000]\n",
      "loss: 0.177925  [40100/60000]\n",
      "loss: 0.010414  [40200/60000]\n",
      "loss: 1.143928  [40300/60000]\n",
      "loss: 0.016915  [40400/60000]\n",
      "loss: 0.040765  [40500/60000]\n",
      "loss: 0.169432  [40600/60000]\n",
      "loss: 0.522534  [40700/60000]\n",
      "loss: 0.321919  [40800/60000]\n",
      "loss: 0.610140  [40900/60000]\n",
      "loss: 0.211821  [41000/60000]\n",
      "loss: 0.296315  [41100/60000]\n",
      "loss: 2.030153  [41200/60000]\n",
      "loss: 0.283351  [41300/60000]\n",
      "loss: 2.021690  [41400/60000]\n",
      "loss: 2.044354  [41500/60000]\n",
      "loss: 0.025479  [41600/60000]\n",
      "loss: 0.954167  [41700/60000]\n",
      "loss: 0.041083  [41800/60000]\n",
      "loss: 0.405100  [41900/60000]\n",
      "loss: 0.010434  [42000/60000]\n",
      "loss: 0.140566  [42100/60000]\n",
      "loss: 0.267439  [42200/60000]\n",
      "loss: 0.011856  [42300/60000]\n",
      "loss: 1.230672  [42400/60000]\n",
      "loss: 0.030156  [42500/60000]\n",
      "loss: 0.119371  [42600/60000]\n",
      "loss: 0.022131  [42700/60000]\n",
      "loss: 0.576375  [42800/60000]\n",
      "loss: 0.134479  [42900/60000]\n",
      "loss: 0.186823  [43000/60000]\n",
      "loss: 0.563379  [43100/60000]\n",
      "loss: 0.748715  [43200/60000]\n",
      "loss: 0.035429  [43300/60000]\n",
      "loss: 0.146830  [43400/60000]\n",
      "loss: 0.070269  [43500/60000]\n",
      "loss: 0.680104  [43600/60000]\n",
      "loss: 0.415008  [43700/60000]\n",
      "loss: 0.130060  [43800/60000]\n",
      "loss: 0.627680  [43900/60000]\n",
      "loss: 0.033142  [44000/60000]\n",
      "loss: 0.180710  [44100/60000]\n",
      "loss: 0.069168  [44200/60000]\n",
      "loss: 0.543772  [44300/60000]\n",
      "loss: 0.125792  [44400/60000]\n",
      "loss: 0.321303  [44500/60000]\n",
      "loss: 0.286377  [44600/60000]\n",
      "loss: 0.009195  [44700/60000]\n",
      "loss: 0.494319  [44800/60000]\n",
      "loss: 0.002784  [44900/60000]\n",
      "loss: 0.642373  [45000/60000]\n",
      "loss: 0.115986  [45100/60000]\n",
      "loss: 0.005396  [45200/60000]\n",
      "loss: 0.024562  [45300/60000]\n",
      "loss: 0.090536  [45400/60000]\n",
      "loss: 0.271732  [45500/60000]\n",
      "loss: 0.664478  [45600/60000]\n",
      "loss: 0.245040  [45700/60000]\n",
      "loss: 5.656640  [45800/60000]\n",
      "loss: 0.052650  [45900/60000]\n",
      "loss: 0.203290  [46000/60000]\n",
      "loss: 0.246102  [46100/60000]\n",
      "loss: 0.210065  [46200/60000]\n",
      "loss: 5.227724  [46300/60000]\n",
      "loss: 0.386964  [46400/60000]\n",
      "loss: 0.078323  [46500/60000]\n",
      "loss: 0.375743  [46600/60000]\n",
      "loss: 0.230662  [46700/60000]\n",
      "loss: 0.916246  [46800/60000]\n",
      "loss: 0.037444  [46900/60000]\n",
      "loss: 0.106370  [47000/60000]\n",
      "loss: 0.542792  [47100/60000]\n",
      "loss: 0.130851  [47200/60000]\n",
      "loss: 0.309644  [47300/60000]\n",
      "loss: 0.018921  [47400/60000]\n",
      "loss: 0.019659  [47500/60000]\n",
      "loss: 2.144166  [47600/60000]\n",
      "loss: 0.021583  [47700/60000]\n",
      "loss: 0.006707  [47800/60000]\n",
      "loss: 0.003666  [47900/60000]\n",
      "loss: 0.139826  [48000/60000]\n",
      "loss: 0.004166  [48100/60000]\n",
      "loss: 0.155862  [48200/60000]\n",
      "loss: 0.045221  [48300/60000]\n",
      "loss: 0.248129  [48400/60000]\n",
      "loss: 0.299483  [48500/60000]\n",
      "loss: 0.004394  [48600/60000]\n",
      "loss: 0.070773  [48700/60000]\n",
      "loss: 0.560319  [48800/60000]\n",
      "loss: 0.244149  [48900/60000]\n",
      "loss: 0.064438  [49000/60000]\n",
      "loss: 0.161967  [49100/60000]\n",
      "loss: 2.195622  [49200/60000]\n",
      "loss: 4.541289  [49300/60000]\n",
      "loss: 0.378729  [49400/60000]\n",
      "loss: 0.338446  [49500/60000]\n",
      "loss: 0.020079  [49600/60000]\n",
      "loss: 0.290805  [49700/60000]\n",
      "loss: 0.526038  [49800/60000]\n",
      "loss: 0.151485  [49900/60000]\n",
      "loss: 0.216781  [50000/60000]\n",
      "loss: 0.105673  [50100/60000]\n",
      "loss: 0.008502  [50200/60000]\n",
      "loss: 0.044585  [50300/60000]\n",
      "loss: 0.027791  [50400/60000]\n",
      "loss: 0.423636  [50500/60000]\n",
      "loss: 0.014860  [50600/60000]\n",
      "loss: 0.487181  [50700/60000]\n",
      "loss: 0.204311  [50800/60000]\n",
      "loss: 0.072571  [50900/60000]\n",
      "loss: 0.034979  [51000/60000]\n",
      "loss: 0.383311  [51100/60000]\n",
      "loss: 1.559858  [51200/60000]\n",
      "loss: 2.495949  [51300/60000]\n",
      "loss: 0.297892  [51400/60000]\n",
      "loss: 0.061605  [51500/60000]\n",
      "loss: 1.104948  [51600/60000]\n",
      "loss: 0.035254  [51700/60000]\n",
      "loss: 0.184340  [51800/60000]\n",
      "loss: 0.012478  [51900/60000]\n",
      "loss: 0.401509  [52000/60000]\n",
      "loss: 0.616215  [52100/60000]\n",
      "loss: 0.185085  [52200/60000]\n",
      "loss: 0.002661  [52300/60000]\n",
      "loss: 0.007685  [52400/60000]\n",
      "loss: 0.204256  [52500/60000]\n",
      "loss: 0.421743  [52600/60000]\n",
      "loss: 0.025263  [52700/60000]\n",
      "loss: 3.982630  [52800/60000]\n",
      "loss: 0.459041  [52900/60000]\n",
      "loss: 0.038471  [53000/60000]\n",
      "loss: 0.046897  [53100/60000]\n",
      "loss: 0.085419  [53200/60000]\n",
      "loss: 0.389462  [53300/60000]\n",
      "loss: 0.010256  [53400/60000]\n",
      "loss: 0.461132  [53500/60000]\n",
      "loss: 0.241727  [53600/60000]\n",
      "loss: 0.034340  [53700/60000]\n",
      "loss: 0.123099  [53800/60000]\n",
      "loss: 0.225708  [53900/60000]\n",
      "loss: 1.204638  [54000/60000]\n",
      "loss: 0.038264  [54100/60000]\n",
      "loss: 0.149290  [54200/60000]\n",
      "loss: 0.076702  [54300/60000]\n",
      "loss: 1.088612  [54400/60000]\n",
      "loss: 0.020788  [54500/60000]\n",
      "loss: 0.072537  [54600/60000]\n",
      "loss: 0.021097  [54700/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.005855  [54800/60000]\n",
      "loss: 0.051005  [54900/60000]\n",
      "loss: 0.023456  [55000/60000]\n",
      "loss: 0.043060  [55100/60000]\n",
      "loss: 0.071852  [55200/60000]\n",
      "loss: 0.004640  [55300/60000]\n",
      "loss: 0.160916  [55400/60000]\n",
      "loss: 0.158157  [55500/60000]\n",
      "loss: 0.060879  [55600/60000]\n",
      "loss: 0.008059  [55700/60000]\n",
      "loss: 0.139655  [55800/60000]\n",
      "loss: 0.033397  [55900/60000]\n",
      "loss: 0.025600  [56000/60000]\n",
      "loss: 0.011606  [56100/60000]\n",
      "loss: 0.033751  [56200/60000]\n",
      "loss: 3.349881  [56300/60000]\n",
      "loss: 0.025990  [56400/60000]\n",
      "loss: 0.027315  [56500/60000]\n",
      "loss: 3.878091  [56600/60000]\n",
      "loss: 0.030100  [56700/60000]\n",
      "loss: 3.537750  [56800/60000]\n",
      "loss: 0.038979  [56900/60000]\n",
      "loss: 0.000256  [57000/60000]\n",
      "loss: 0.567515  [57100/60000]\n",
      "loss: 0.038640  [57200/60000]\n",
      "loss: 0.107266  [57300/60000]\n",
      "loss: 0.088119  [57400/60000]\n",
      "loss: 0.001174  [57500/60000]\n",
      "loss: 0.002655  [57600/60000]\n",
      "loss: 0.045239  [57700/60000]\n",
      "loss: 0.046911  [57800/60000]\n",
      "loss: 0.316198  [57900/60000]\n",
      "loss: 0.119014  [58000/60000]\n",
      "loss: 0.813315  [58100/60000]\n",
      "loss: 0.002708  [58200/60000]\n",
      "loss: 0.155841  [58300/60000]\n",
      "loss: 0.109686  [58400/60000]\n",
      "loss: 0.003095  [58500/60000]\n",
      "loss: 0.007958  [58600/60000]\n",
      "loss: 0.031759  [58700/60000]\n",
      "loss: 0.245733  [58800/60000]\n",
      "loss: 0.839846  [58900/60000]\n",
      "loss: 0.038072  [59000/60000]\n",
      "loss: 0.006117  [59100/60000]\n",
      "loss: 0.012892  [59200/60000]\n",
      "loss: 0.003760  [59300/60000]\n",
      "loss: 1.282638  [59400/60000]\n",
      "loss: 0.015390  [59500/60000]\n",
      "loss: 0.051569  [59600/60000]\n",
      "loss: 0.002442  [59700/60000]\n",
      "loss: 0.008758  [59800/60000]\n",
      "loss: 0.036972  [59900/60000]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nw/8yyyyp8n70vbplhdsylyqs8c0000gn/T/ipykernel_4624/1811241004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6d832",
   "metadata": {},
   "source": [
    "##### Yikes!  Ok now see why batch size is needed for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fb0a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "493defdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.376924  [    0/60000]\n",
      "loss: 0.319363  [ 6400/60000]\n",
      "loss: 0.241200  [12800/60000]\n",
      "loss: 0.373960  [19200/60000]\n",
      "loss: 0.368900  [25600/60000]\n",
      "loss: 0.373416  [32000/60000]\n",
      "loss: 0.215285  [38400/60000]\n",
      "loss: 0.332208  [44800/60000]\n",
      "loss: 0.297689  [51200/60000]\n",
      "loss: 0.377219  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.319167 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.334014  [    0/60000]\n",
      "loss: 0.307796  [ 6400/60000]\n",
      "loss: 0.231161  [12800/60000]\n",
      "loss: 0.371427  [19200/60000]\n",
      "loss: 0.360897  [25600/60000]\n",
      "loss: 0.348333  [32000/60000]\n",
      "loss: 0.201599  [38400/60000]\n",
      "loss: 0.341924  [44800/60000]\n",
      "loss: 0.281649  [51200/60000]\n",
      "loss: 0.369607  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.310508 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.317849  [    0/60000]\n",
      "loss: 0.300507  [ 6400/60000]\n",
      "loss: 0.227408  [12800/60000]\n",
      "loss: 0.369562  [19200/60000]\n",
      "loss: 0.354561  [25600/60000]\n",
      "loss: 0.335497  [32000/60000]\n",
      "loss: 0.194021  [38400/60000]\n",
      "loss: 0.344353  [44800/60000]\n",
      "loss: 0.269996  [51200/60000]\n",
      "loss: 0.363528  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.303923 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.306392  [    0/60000]\n",
      "loss: 0.293644  [ 6400/60000]\n",
      "loss: 0.223284  [12800/60000]\n",
      "loss: 0.366322  [19200/60000]\n",
      "loss: 0.347542  [25600/60000]\n",
      "loss: 0.325801  [32000/60000]\n",
      "loss: 0.187362  [38400/60000]\n",
      "loss: 0.344371  [44800/60000]\n",
      "loss: 0.259934  [51200/60000]\n",
      "loss: 0.358505  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.298122 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.296639  [    0/60000]\n",
      "loss: 0.287032  [ 6400/60000]\n",
      "loss: 0.218340  [12800/60000]\n",
      "loss: 0.362510  [19200/60000]\n",
      "loss: 0.340754  [25600/60000]\n",
      "loss: 0.316599  [32000/60000]\n",
      "loss: 0.180879  [38400/60000]\n",
      "loss: 0.343430  [44800/60000]\n",
      "loss: 0.251751  [51200/60000]\n",
      "loss: 0.353371  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.292807 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.288134  [    0/60000]\n",
      "loss: 0.280483  [ 6400/60000]\n",
      "loss: 0.213074  [12800/60000]\n",
      "loss: 0.358507  [19200/60000]\n",
      "loss: 0.333870  [25600/60000]\n",
      "loss: 0.307935  [32000/60000]\n",
      "loss: 0.174816  [38400/60000]\n",
      "loss: 0.341670  [44800/60000]\n",
      "loss: 0.244476  [51200/60000]\n",
      "loss: 0.348475  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.287769 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.280311  [    0/60000]\n",
      "loss: 0.274370  [ 6400/60000]\n",
      "loss: 0.207641  [12800/60000]\n",
      "loss: 0.354136  [19200/60000]\n",
      "loss: 0.327209  [25600/60000]\n",
      "loss: 0.300028  [32000/60000]\n",
      "loss: 0.169224  [38400/60000]\n",
      "loss: 0.339569  [44800/60000]\n",
      "loss: 0.237737  [51200/60000]\n",
      "loss: 0.343707  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.282982 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.272980  [    0/60000]\n",
      "loss: 0.268492  [ 6400/60000]\n",
      "loss: 0.202104  [12800/60000]\n",
      "loss: 0.349652  [19200/60000]\n",
      "loss: 0.321063  [25600/60000]\n",
      "loss: 0.292568  [32000/60000]\n",
      "loss: 0.164022  [38400/60000]\n",
      "loss: 0.337238  [44800/60000]\n",
      "loss: 0.231238  [51200/60000]\n",
      "loss: 0.339191  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.278384 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.265957  [    0/60000]\n",
      "loss: 0.262892  [ 6400/60000]\n",
      "loss: 0.196805  [12800/60000]\n",
      "loss: 0.345299  [19200/60000]\n",
      "loss: 0.314814  [25600/60000]\n",
      "loss: 0.285536  [32000/60000]\n",
      "loss: 0.158841  [38400/60000]\n",
      "loss: 0.334626  [44800/60000]\n",
      "loss: 0.225211  [51200/60000]\n",
      "loss: 0.334868  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.273905 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.259297  [    0/60000]\n",
      "loss: 0.257312  [ 6400/60000]\n",
      "loss: 0.191360  [12800/60000]\n",
      "loss: 0.341165  [19200/60000]\n",
      "loss: 0.308955  [25600/60000]\n",
      "loss: 0.278869  [32000/60000]\n",
      "loss: 0.153742  [38400/60000]\n",
      "loss: 0.332077  [44800/60000]\n",
      "loss: 0.219969  [51200/60000]\n",
      "loss: 0.330900  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.269568 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
